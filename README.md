# DocMind â€” AI Document Q&A

Upload PDFs, ask questions, get accurate answers with source citations.
Supports 6 AI providers and multiple models per provider.

**Live Demo:** [doc-mind-ai-document-q-a.vercel.app](https://doc-mind-ai-document-q-a.vercel.app)
**Medium Blog:** [medium.com/@kethanpabbi/i-built-docmind-anai-document-q-a-system-that-supports-6-llm-providers](https://medium.com/@kethanpabbi/i-built-docmind-anai-document-q-a-system-that-supports-6-llm-providers-heres-how-de0182856340)
---

## Features

- ğŸ“„ Upload one or multiple PDFs
- ğŸ¤– Choose from 6 AI providers and multiple models
- ğŸ’¬ Ask questions in natural language
- ğŸ“ Get answers with page-level source citations
- ğŸ”‘ Users bring their own API key â€” zero cost to you
- âš¡ Fast retrieval via ChromaDB vector search

---

## Supported Providers & Models

| Provider   | Models |
|------------|--------|
| ğŸ¤– Anthropic | Claude Haiku 3.5 (cheapest), Claude Sonnet 4 (best) |
| âš¡ OpenAI   | GPT-4o Mini (cheapest), GPT-4o (best), GPT-4 Turbo, o1 Mini |
| ğŸ”· Google   | Gemini 1.5 Flash (cheapest), Gemini 1.5 Pro (best), Gemini 2.0 Flash |
| ğŸŒªï¸ Mistral  | Mistral Small (cheapest), Mistral Large (best), Codestral |
| ğŸŒŠ Cohere   | Command R (cheapest), Command R+ (best) |
| ğŸš€ Groq     | Llama 3.1 8B (cheapest), Llama 3.3 70B (best), Mixtral 8x7B |

---

## Tech Stack

**Backend:** FastAPI Â· ChromaDB Â· LangChain Â· pypdf Â· Python 3.11
**Frontend:** Vanilla HTML/CSS/JS (no framework)
**Deployment:** Railway (backend) Â· Vercel (frontend)

---

## Project Structure

```
document-qa-v2/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py            # FastAPI app â€” upload, query, provider routing
â”‚   â”œâ”€â”€ requirements.txt   # Python dependencies
â”‚   â””â”€â”€ Procfile           # Railway start command
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html         # Full UI â€” provider/model selector, chat
â”‚   â””â”€â”€ vercel.json        # Vercel deployment config
â””â”€â”€ README.md
```

---

## How It Works

```
PDF upload â†’ text extraction â†’ chunking (1000 chars, 150 overlap)
          â†’ ChromaDB embeddings â†’ stored in vector DB

Question â†’ embed query â†’ retrieve top 4 chunks
         â†’ send to chosen AI provider â†’ answer with source citations
```

---

## Deployment

### Backend â†’ Railway
1. Push repo to GitHub
2. Go to railway.app â†’ New Project â†’ Deploy from GitHub
3. Set Root Directory to `backend`
4. Railway auto-detects Python and runs the Procfile
5. Go to Settings â†’ Networking â†’ Generate Domain â†’ set port to `8080`
6. Copy your Railway URL

### Frontend â†’ Vercel
1. Open `frontend/index.html`
2. Replace `API_BASE` with your Railway URL:
   ```js
   const API_BASE = "https://your-app.up.railway.app";
   ```
3. Go to vercel.com â†’ New Project â†’ Import from GitHub
4. Set Root Directory to `frontend`
5. Deploy â€” get your live Vercel URL

---

## Local Development

```bash
cd backend
pip3.11 install -r requirements.txt
uvicorn main:app --reload
```

In `frontend/index.html` set:
```js
const API_BASE = "http://localhost:8000";
```

Then open `frontend/index.html` directly in your browser.

---

## Getting API Keys

| Provider  | Link |
|-----------|------|
| Anthropic | https://console.anthropic.com |
| OpenAI    | https://platform.openai.com/api-keys |
| Google    | https://aistudio.google.com/app/apikey |
| Mistral   | https://console.mistral.ai/api-keys |
| Cohere    | https://dashboard.cohere.com/api-keys |
| Groq      | https://console.groq.com/keys |
